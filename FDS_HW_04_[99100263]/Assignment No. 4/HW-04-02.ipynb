{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4. Deep Learning\n",
    "\n",
    "*Foundations of Data Science*  \n",
    "*Dr. Khalaj (Fall 2023)*  \n",
    "\n",
    "*For questions 2-4 refer to @alregamo on Telegram.*\n",
    "\n",
    "### Description  \n",
    "This homework consists of four questions, each aimed at one category in the world of Deep Learning.   \n",
    "1. Getting familiarized with sentiment analysis (A subject also covered in the course project).\n",
    "   \n",
    "2. Multi-layer perceptron (MLP). \n",
    "   \n",
    "3. Convolutional Neural Networks (CNN).\n",
    "   \n",
    "4. Variational Autoencoders (VAE).\n",
    "\n",
    "### Information  \n",
    "Complete the information box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name = 'Hadi Hadavi'\n",
    "student_id = '99100263'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "The questions are not necessarily in order of difficulty. You are obligated to answer **3 out of 4** questions. The fourth question is optional and is considered as bonus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Multi-layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this assignment you'll be working with Dorothea Dataset.**\n",
    "\n",
    "DOROTHEA is a drug discovery dataset. Chemical compounds represented by structural molecular features must be classified as active (binding to thrombin) or inactive. To find out more about dataset, refer to this link: https://archive.ics.uci.edu/ml/datasets/Dorothea\n",
    "\n",
    "You should implement a classifier with Neural Networks and for this purpose we will be using PyTorch as framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing libraries, modules and Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, import all the libraries and modules needed to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import the train and test data from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Normalize\n",
    "You can normalize your data using <code>Scikit-Learn</code> modules here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Dimensionality Reduction\n",
    "There are too many attributes for each instance of dataset. We will suffer from sparse data and long training phase. Thus you can reduce dimensions to get better accuracy. \n",
    "\n",
    "Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data.\n",
    "\n",
    "Apply PCA on Dorothea dataSet using <code>Scikit-Learn</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Define Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model in here\n",
    "# You can change the code below.\n",
    "\n",
    "class ClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize model, define hyperparameters, optimizer, loss function, etc.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Train in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After the training process, plot metrics such as loss function values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Testing\n",
    "After training, test your model on test dataset and compute performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Test in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show confusion matrix of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print your confusion matrix here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
